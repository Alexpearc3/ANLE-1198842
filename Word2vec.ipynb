{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-05T03:25:02.067787Z",
     "end_time": "2023-05-05T03:25:02.257938Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'nltk' has no attribute 'download'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 11\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Word2Vec\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# Download the 'punkt' resource\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m \u001B[43mnltk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload\u001B[49m()\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m     13\u001B[0m train_data\u001B[38;5;241m=\u001B[39mpd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpropaganda_train.tsv\u001B[39m\u001B[38;5;124m'\u001B[39m,sep\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'nltk' has no attribute 'download'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import tokenize\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from gensim.models import Word2Vec\n",
    "# Download the 'punkt' resource\n",
    "nltk.download()\n",
    "import os\n",
    "train_data=pd.read_csv('propaganda_train.tsv',sep='\\t')\n",
    "test_data=pd.read_csv('propaganda_val.tsv',sep='\\t')\n",
    "print(train_data)\n",
    "print(train_data)\n",
    "training_df=pd.DataFrame(train_data,columns=[\"tagged_in_context\",\"label\"])\n",
    "testing_df=pd.DataFrame(test_data,columns=[\"tagged_in_context\",\"label\"])\n",
    "\n",
    "print(training_df)\n",
    "labellist=sorted(list(set(training_df['label'].unique()).union(set(testing_df['label'].unique()))))\n",
    "\n",
    "labels={label:i for i,label in enumerate(labellist)}\n",
    "labels\n",
    "reverse_index={value:key for (key,value)in labels.items()}\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "training_df['sentences'] = training_df['tagged_in_context'].apply(lambda x: nltk.tokenize.word_tokenize(x.lower()))\n",
    "training_df['binary_label'] = (training_df['label'] != 'not_propaganda').astype(int)\n",
    "\n",
    "# Train the Word2Vec model\n",
    "model = Word2Vec(sentences=train_data['sentences'], vector_size=100, window=5, min_count=1, workers=4)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a function to convert a sentence to a feature vector\n",
    "def sentence_to_feature_vector(sentence, word2vec_model):\n",
    "    feature_vector = np.zeros(word2vec_model.vector_size)\n",
    "    count = 0\n",
    "    for word in sentence:\n",
    "        if word in word2vec_model.wv:\n",
    "            feature_vector += word2vec_model.wv[word]\n",
    "            count += 1\n",
    "    return feature_vector / count if count != 0 else feature_vector"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert the sentences to feature vectors\n",
    "train_vectors = np.vstack(train_data['sentences'].apply(lambda x: sentence_to_feature_vector(x, model)))\n",
    "test_vectors = np.vstack(test_data['sentences'].apply(lambda x: sentence_to_feature_vector(x, model)))\n",
    "\n",
    "# Train the logistic regression classifier\n",
    "clf = LogisticRegression(random_state=42).fit(train_vectors, train_data['binary_label'])\n",
    "\n",
    "# Make predictions and evaluate the performance\n",
    "predictions = clf.predict(test_vectors)\n",
    "print(classification_report(test_data['binary_label'], predictions))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "use_cuda=torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "  print(\"GPU acceleration enabled\")\n",
    "else:\n",
    "  print(\"GPU acceleration NOT enabled.  If using Colab, have you changed the runtype type and selected GPU as the hardware accelerator?\")\n",
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "# get number of GPUs available\n",
    "torch.cuda.device_count() # returns 1 in my case\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-05T03:34:05.181452Z",
     "end_time": "2023-05-05T03:34:08.526922Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nltk in c:\\users\\alex1\\anaconda3\\envs\\gpunle\\lib\\site-packages (3.7)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\alex1\\anaconda3\\envs\\gpunle\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\alex1\\anaconda3\\envs\\gpunle\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: click in c:\\users\\alex1\\anaconda3\\envs\\gpunle\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\alex1\\anaconda3\\envs\\gpunle\\lib\\site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\alex1\\anaconda3\\envs\\gpunle\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Installing collected packages: nltk\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.7\n",
      "    Uninstalling nltk-3.7:\n",
      "      Successfully uninstalled nltk-3.7\n",
      "Successfully installed nltk-3.8.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall nltk\n",
    "%pip install -U nltk"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-05T03:37:06.200609Z",
     "end_time": "2023-05-05T03:45:24.417840Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
